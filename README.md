# Comprehensive regression-ml-dl-genai-app

An interactive regression analysis platform powered by **Machine Learning**, **Deep Learning**, and **Generative AI** ‚Äî built with **Streamlit** for real-time, explainable model exploration.

---

## Project Summary

This project demonstrates a complete workflow for regression modeling using both **traditional ML algorithms** and **Deep Learning architectures**, enhanced by **Generative AI (OpenAI GPT)** to explain predictions and metrics in human-friendly language.

Designed as a modular, production-style app, this solution enables users to:
- Upload and preprocess their own data
- Select and compare regression models
- Visualize model performance
- Understand predictions with the help of a GenAI assistant

---

## üéØ Key Features

| Feature | Description |
|--------|-------------|
| **ML & DL Models** | Train & evaluate Linear Regression, Random Forest, and Deep Neural Networks |
| **Model Evaluation** | Automatically computes metrics like RMSE, MAE, R¬≤, and plots |
| **GenAI Explanation** | Uses OpenAI GPT to generate plain-language descriptions of the models |
| **Interactive UI** | Built with Streamlit for easy interaction and dynamic insights |
| **Data Upload** | Accepts CSV data
---

## Technologies Used

- **Scikit-learn**: Linear Regression, Random Forest
- **TensorFlow / Keras**: Deep Learning regression model
- **Pandas & Matplotlib**: Data manipulation and visualization
- **Streamlit**: Interactive web app
- **OpenAI GPT (via API)**: Model explanation using Generative AI

---

## Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/sivkri/regression-ml-dl-genai-app.git
cd regression-ml-dl-genai-app
```
### 2. Install the requirements

```bash
pip install -r requirements.txt
```
### 3. Get your OpenAI API key

Go to OpenAI API keys

you can input the key securely via the app if prompted.

### 4. Run the Streamlit app

```bash
streamlit run streamlit_app.py
```
## How It Works

**Upload CSV Data**: Choose a CSV file with numeric features and a continuous target.

**Choose Model**: Select between ML (Linear Regression, Random Forest) or DL (Keras DNN).

**Model Training**: Train and evaluate the model.

**Visualization**: Plot actual vs predicted values, feature importance, etc.

**Explain with GenAI**: Generate human-friendly summaries and insights using GPT.

## Sample Outputs

- Scatter plots of predictions

- Evaluation metrics (MAE, RMSE, R¬≤)

- GPT-generated explanations of model performance

- Highlighted prediction confidence and anomalies

## Generative AI Integration
The GenAI assistant uses the OpenAI API (GPT-3.5/4) to generate:

  Explanation of model performance

  Suggestions on data preprocessing

  Interpretations of model predictions in natural language

----
### ‚öñÔ∏è ML vs DL: Side-by-Side Comparison

| üîç Aspect                    | üß† ML (XGBoost, RF, Stacking)                 | ü§ñ DL (Deep Neural Network)                          |
|-----------------------------|-----------------------------------------------|------------------------------------------------------|
| **Model Type**              | Ensemble of Decision Trees (XGBoost, RF) +Linear Stacking                    | Multi-layer feedforward neural network              |
| **Feature Engineering**     | Manual (RoomsPerPerson, LogPopulation)                    | Same manual features used                           |
| **Outlier Handling**        | Z-score or IQR-based filtering                | Same method                                          |
| **Feature Scaling**         | Optional (needed for linear models)           | Required (for better convergence)                   |
| **Hyperparameter Tuning**  | GridSearch / RandomSearchCV                   | Layer tuning + callbacks                            |
| **Regularization**          | Tree constraints, early stopping              | L2, Dropout, EarlyStopping                          |
| **Training Control**        | Cross-validation, early stopping              | EarlyStopping, ReduceLROnPlateau, Checkpoints       |
| **Explainability**          | ‚úÖ SHAP/LIME available  for feature importance                        | ‚ùå Harder (need external tools like LIME, tf-explain)|
| **Training Speed**          | Fast on small/medium datasets                        | Slower due to many epochs                           |
| **Scalability**             | Easy to scale (tree-based)                       | Great with GPU on large data                        |
| **Interpretability**        | High (especially with SHAP)                   | Low unless explained manually                       |
| **Overfitting Risk**        | Moderate (trees handle it better)             | High without proper regularization                  |
| **Custom Layers/Complexity**             | Less flexible (fixed structure)               | Highly flexible (custom layers, losses, etc.)       |

-----

### When to Use What?

| Use Case                                     | ‚úÖ Choose ML (Tree-based models, etc.) | ‚úÖ Choose DL (Neural Networks)         |
|---------------------------------------------|----------------------------------------|----------------------------------------|
| **Structured/tabular data**                 | ‚úÖ Excellent performance                | ‚ö†Ô∏è Works, but often overkill            |
| **Need explainability**                     | ‚úÖ SHAP, easily interpretable           | ‚ùå Requires extra tools like LIME/SHAP  |
| **Small to medium dataset**                 | ‚úÖ Fast and efficient                   | ‚ö†Ô∏è Risk of overfitting, slower training |
| **Large-scale, complex dataset**            | ‚ö†Ô∏è May not scale well                  | ‚úÖ Scales well with GPU                 |
| **Unstructured data (images, text, audio)** | ‚ùå Not suitable                         | ‚úÖ Ideal choice                         |
| **Quick prototyping**                       | ‚úÖ Minimal tuning needed                | ‚ùå Needs architecture/hyperparameter tuning |
| **Limited compute resources**               | ‚úÖ Lightweight models                   | ‚ùå Needs more memory/time               |
| **Business-friendly interpretation needed** | ‚úÖ High interpretability                | ‚ùå Black-box unless explained further   |
| **Want to ensemble or stack models**        | ‚úÖ Works very well                      | ‚ö†Ô∏è Can be complex to ensemble           |

  
